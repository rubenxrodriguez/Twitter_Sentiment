{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset information\n",
    "This is the sentiment140 dataset.\n",
    "* It contains 1,600,000 tweets extracted using the twitter api . \n",
    "* The tweets have been annotated (0 = negative, 4 = positive) and they can be used to detect sentiment .\n",
    "* It contains the following 6 fields:\n",
    "   - target: the polarity of the tweet (0 = negative, 4 = positive)\n",
    "   - ids: The id of the tweet ( 2087)\n",
    "   - date: the date of the tweet (Sat May 16 23:58:44 UTC 2009)\n",
    "   - flag: The query (lyx). If there is no query, then this value is NO_QUERY.\n",
    "   - user: the user that tweeted (robotickilldozr)\n",
    "   - text: the text of the tweet (Lyx is cool) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 of NLP : Add the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 of NLP : Set a random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 of NLP : Add the Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>time</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label        time                          date     query       username  \\\n",
       "0      0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY  scotthamilton   \n",
       "1      0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY       mattycus   \n",
       "2      0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY        ElleCTF   \n",
       "3      0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY         Karoli   \n",
       "4      0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY       joy_wolf   \n",
       "\n",
       "                                                text  \n",
       "0  is upset that he can't update his Facebook by ...  \n",
       "1  @Kenichan I dived many times for the ball. Man...  \n",
       "2    my whole body feels itchy and like its on fire   \n",
       "3  @nationwideclass no, it's not behaving at all....  \n",
       "4                      @Kwesidei not the whole crew   "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"tweet_sentiments.csv\")\n",
    "data.columns = ['label','time','date','query','username','text']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>time</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1599994</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601966</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AmandaMarie1028</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601969</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>TheWDBoards</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601991</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>bpbabe</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602064</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>tinydiamondz</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602129</td>\n",
       "      <td>Tue Jun 16 08:40:50 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>RyanTrevMorris</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         label        time                          date     query  \\\n",
       "1599994      4  2193601966  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599995      4  2193601969  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599996      4  2193601991  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599997      4  2193602064  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599998      4  2193602129  Tue Jun 16 08:40:50 PDT 2009  NO_QUERY   \n",
       "\n",
       "                username                                               text  \n",
       "1599994  AmandaMarie1028  Just woke up. Having no school is the best fee...  \n",
       "1599995      TheWDBoards  TheWDB.com - Very cool to hear old Walt interv...  \n",
       "1599996           bpbabe  Are you ready for your MoJo Makeover? Ask me f...  \n",
       "1599997     tinydiamondz  Happy 38th Birthday to my boo of alll time!!! ...  \n",
       "1599998   RyanTrevMorris  happy #charitytuesday @theNSPCC @SparksCharity...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['label', 'time', 'date', 'query', 'username', 'text'], dtype='object')\n",
      "length of data is  1599999\n",
      "shape of data is  (1599999, 6)\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)\n",
    "print('length of data is ', len(data))\n",
    "print('shape of data is ',data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label        int64\n",
      "time         int64\n",
      "date        object\n",
      "query       object\n",
      "username    object\n",
      "text        object\n",
      "dtype: object\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(data.dtypes)\n",
    "print(np.sum(data.isnull().any(axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 of NLP : Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We only care about the text and label columns, and we're going to take a subset to reduce run time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qh/zhr4gq8s5px2ff46zwfdk90hy3y30j/T/ipykernel_51705/1375667621.py:2: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['label'][data['label']==4]=1 # assign 1 to positive sentiment and leave 0 as negative sentiment\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1599994</th>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  label\n",
       "1599994  Just woke up. Having no school is the best fee...      1\n",
       "1599995  TheWDB.com - Very cool to hear old Walt interv...      1\n",
       "1599996  Are you ready for your MoJo Makeover? Ask me f...      1\n",
       "1599997  Happy 38th Birthday to my boo of alll time!!! ...      1\n",
       "1599998  happy #charitytuesday @theNSPCC @SparksCharity...      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[['text','label']]\n",
    "data['label'][data['label']==4]=1 # assign 1 to positive sentiment and leave 0 as negative sentiment\n",
    "\n",
    "#make statement in lower case\n",
    "data['text'] = data['text'].str.lower()\n",
    "\n",
    "data_pos = data[data['label']==1]\n",
    "data_neg = data[data['label']==0]\n",
    "#take subset of our data so our machine can run easily\n",
    "data_pos = data_pos.iloc[:int(250000)]\n",
    "data_neg = data_neg.iloc[:int(250000)]\n",
    "\n",
    "data = pd.concat([data_pos,data_neg])\n",
    "\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>249995</th>\n",
       "      <td>bah to much water in cofe again</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249996</th>\n",
       "      <td>lunch with analt then swiming maybe blah heada...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249997</th>\n",
       "      <td>blazinsquadnews oh no im sory for you i hope y...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249998</th>\n",
       "      <td>a want ice cream</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249999</th>\n",
       "      <td>tamarzipan haha i couldnt my dad is watching tv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  label\n",
       "249995                   bah to much water in cofe again       0\n",
       "249996  lunch with analt then swiming maybe blah heada...      0\n",
       "249997  blazinsquadnews oh no im sory for you i hope y...      0\n",
       "249998                                  a want ice cream       0\n",
       "249999   tamarzipan haha i couldnt my dad is watching tv       0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    return re.sub(r'[^a-zA-Z\\s]', '', text)  # Keeps only letters and spaces\n",
    "\n",
    "def cleaning_repeating_char(text):\n",
    "    return re.sub(r'(.)\\1+', r'\\1', text)\n",
    "\n",
    "data['text'] = data['text'].apply(lambda x : clean_text(x))\n",
    "data['text'] = data['text'].apply(lambda x : cleaning_repeating_char(x))\n",
    "\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 of NLP : Prepare Train and Test Data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['text'], data['label'], test_size=0.4, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6 of NLP : Encoding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Not necessary because the label column in our data set is already numerical "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7 of NLP : Word Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)  # Convert text to numerical features\n",
    "X_test = vectorizer.transform(X_test)  # Labels (0 = Negative, 1 = Positive)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7 : Use the ML Algorithms to Predict the Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Multinomial Model: 0.77443\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train Multinomial Naive Bayes\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy of Multinomial Model: {accuracy:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "new_tweets = [\"I am naive\", \"Turtles are overrated\", \"I am at peace\", 'I\\'m a machine']\n",
    "new_X = vectorizer.transform(new_tweets)  # Convert text to numerical features\n",
    "\n",
    "predictions = model.predict(new_X)\n",
    "print(predictions)  # Output: (1=Positive, 0=Negative)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv(\"tweets.csv\")\n",
    "data.columns = ['label', 'time', 'date', 'query', 'username', 'text']\n",
    "data = data[['text', 'label']]\n",
    "\n",
    "# Convert positive sentiment from 4 to 1\n",
    "data['label'] = data['label'].replace(4, 1)\n",
    "\n",
    "# Split positive and negative tweets\n",
    "data_pos = data[data['label'] == 1].iloc[:15000]  # Adjust size as needed\n",
    "data_neg = data[data['label'] == 0].iloc[:15000]\n",
    "data = pd.concat([data_pos,data_neg])\n",
    "\n",
    "# Clean text function\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)  # Remove URLs\n",
    "    text = re.sub(r'@\\w+', '', text)  # Remove mentions\n",
    "    text = re.sub(r'#\\w+', '', text)  # Remove hashtags\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove non-alphabetic characters\n",
    "    return text\n",
    "\n",
    "# Apply text cleaning\n",
    "data['text'] = data['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Now run the model with a Gaussian Naive Bayes approach  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)  # Remove URLs\n",
    "    text = re.sub(r'@\\w+', '', text)  # Remove mentions\n",
    "    text = re.sub(r'#\\w+', '', text)  # Remove hashtags\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove non-alphabetic characters\n",
    "    return text\n",
    "\n",
    "\n",
    "stop_words = {\n",
    "    'i', 'the', 'to', 'a', 'you', 'and', 'my', 'for', 'it', 'is', 'in', 'of', \n",
    "    'on', 'im', 'me', 'that', 'with', 'so', 'have', 'just', 'be', 'its', \n",
    "    'at', 'but','was', 'your', 'are', 'this', 'now'\n",
    "}\n",
    "\n",
    "def make_Dictionary_tweets(tweets):\n",
    "    all_words = []\n",
    "\n",
    "    total_tweets = len(tweets)\n",
    "    print(f\"Total tweets to process: {total_tweets}\")\n",
    "\n",
    "    for idx, tweet in enumerate(tweets):\n",
    "        # Split the tweet into words and add to all_words\n",
    "        words = tweet.split()\n",
    "        all_words += words\n",
    "\n",
    "        # Filter out stop words\n",
    "        all_words = [word for word in all_words if word not in stop_words]\n",
    "\n",
    "        # Print progress every 10% of the dataset\n",
    "        if (idx + 1) % (total_tweets // 10) == 0:\n",
    "            percent_complete = (idx + 1) / total_tweets * 100\n",
    "            print(f\"Processed {idx + 1} tweets ({percent_complete:.1f}%)\")\n",
    "    \n",
    "    dictionary = Counter(all_words)\n",
    "    list_to_remove = list(dictionary)\n",
    "    for item in list_to_remove:\n",
    "        if not item.isalpha() or len(item) == 1:\n",
    "            del dictionary[item]\n",
    "    dictionary = dictionary.most_common(3000)\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tweets to process: 30000\n",
      "Processed 3000 tweets (10.0%)\n",
      "Processed 6000 tweets (20.0%)\n",
      "Processed 9000 tweets (30.0%)\n",
      "Processed 12000 tweets (40.0%)\n",
      "Processed 15000 tweets (50.0%)\n",
      "Processed 18000 tweets (60.0%)\n",
      "Processed 21000 tweets (70.0%)\n",
      "Processed 24000 tweets (80.0%)\n",
      "Processed 27000 tweets (90.0%)\n",
      "Processed 30000 tweets (100.0%)\n"
     ]
    }
   ],
   "source": [
    "dictionary = make_Dictionary_tweets(data['text'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features\n",
    "def extract_features_tweets(tweets, dictionary):\n",
    "    features_matrix = np.zeros((len(tweets), len(dictionary)))\n",
    "    labels = np.zeros(len(tweets))\n",
    "    for docID, tweet in enumerate(tweets):\n",
    "        words = tweet.split()\n",
    "        for i, word in enumerate(dictionary):\n",
    "            features_matrix[docID, i] = words.count(word[0])\n",
    "        # Assign labels (1 for positive, 0 for negative)\n",
    "        labels[docID] = data.iloc[docID]['label']\n",
    "    return features_matrix, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Gaussian Model: 0.6935\n"
     ]
    }
   ],
   "source": [
    "features_matrix, labels = extract_features_tweets(data['text'].tolist(), dictionary)\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_matrix, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Gaussian Naive Bayes\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = gnb.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy of Gaussian Model: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# New tweets to classify\n",
    "new_tweets = [\"Lizards are ugly\", \"I am at peace\", \"I hate certain food\"]\n",
    "\n",
    "# Preprocess the new tweets (use the same clean_text function as before)\n",
    "cleaned_tweets = [clean_text(tweet) for tweet in new_tweets]\n",
    "\n",
    "# Function to convert new tweets into feature vectors using the dictionary\n",
    "def extract_features_new_tweets(tweets, dictionary):\n",
    "    features_matrix = np.zeros((len(tweets), len(dictionary)))\n",
    "    for docID, tweet in enumerate(tweets):\n",
    "        words = tweet.split()\n",
    "        for i, word in enumerate(dictionary):\n",
    "            features_matrix[docID, i] = words.count(word[0])  # word[0] is the word in the dictionary\n",
    "    return features_matrix\n",
    "\n",
    "# Convert new tweets into feature vectors\n",
    "new_X = extract_features_new_tweets(cleaned_tweets, dictionary)\n",
    "\n",
    "# Make predictions\n",
    "predictions = gnb.predict(new_X)\n",
    "# new_tweets = [\"Lizards are ugly\", \"I am at peace\", \"I hate certain food\"]\n",
    "# Print predictions\n",
    "print(predictions)  # Output:[0,1,1]] (1=Positive, 0=Negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Now we train a Bernoulli NB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Bernoulli Model: 0.7795\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['text'], data['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert text to binary feature vectors\n",
    "vectorizer = CountVectorizer(binary=True)  # Use binary=True for BernoulliNB\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Train Bernoulli Naive Bayes model\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train_vec, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = bnb.predict(X_test_vec)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy of Bernoulli Model: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "new_tweets = [\"I am busy\", \"Turtles are ugly\", \"I am horrible\", \"I hate hate\"]\n",
    "cleaned_tweets = [clean_text(tweet) for tweet in new_tweets]\n",
    "new_X = vectorizer.transform(cleaned_tweets)\n",
    "predictions = bnb.predict(new_X)\n",
    "print(predictions)  # Output: [1, 0, 1, 0] (1=Positive, 0=Negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
